{"cells":[{"cell_type":"markdown","metadata":{"id":"mUgf4d4Ih5dC"},"source":["If you have 10 pictures of yourself, simply select them all and rename only one to the chosen identifier for example : phtmejhn, the files would be : phtmejhn (1).jpg, phtmejhn (2).png ....etc then upload them, do the same for other people or objects with a different identifier, and that's it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ooQLMsWngVg0"},"outputs":[],"source":["Session_Name = \"goldhandai\" #@param{type: 'string'}\n","hf_token_write = \"\" #@param {type:\"string\"}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68976,"status":"ok","timestamp":1700651263034,"user":{"displayName":"Mihály Orsós","userId":"13959260843040539293"},"user_tz":-60},"id":"QyvcqeiL65Tj","outputId":"327536bd-bcf8-4a1e-8be8-666acb2ad347"},"outputs":[],"source":["\n","from IPython.utils import capture\n","import time\n","import os\n","\n","print('\u001b[1;32mInstalling dependencies...')\n","with capture.capture_output() as cap:\n","    os.chdir('/content')\n","    !pip install -qq --no-deps accelerate==0.12.0\n","    !wget -q -i https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dependencies/dbdeps.txt\n","    !dpkg -i *.deb\n","    !tar -C / --zstd -xf gcolabdeps.tar.zst\n","    !rm *.deb | rm *.zst | rm *.txt\n","    !git clone -q --depth 1 --branch main https://github.com/TheLastBen/diffusers\n","    !pip install gradio==3.16.2 --no-deps -qq\n","\n","    if not os.path.exists('gdrive/MyDrive/sd/libtcmalloc/libtcmalloc_minimal.so.4'):\n","        %env CXXFLAGS=-std=c++14\n","        !wget -q https://github.com/gperftools/gperftools/releases/download/gperftools-2.5/gperftools-2.5.tar.gz && tar zxf gperftools-2.5.tar.gz && mv gperftools-2.5 gperftools\n","        !wget -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/Patch\n","        %cd /content/gperftools\n","        !patch -p1 < /content/Patch\n","        !./configure --enable-minimal --enable-libunwind --enable-frame-pointers --enable-dynamic-sized-delete-support --enable-sized-delete --enable-emergency-malloc; make -j4\n","        !mkdir -p /content/gdrive/MyDrive/sd/libtcmalloc && cp .libs/libtcmalloc*.so* /content/gdrive/MyDrive/sd/libtcmalloc\n","        %env LD_PRELOAD=/content/gdrive/MyDrive/sd/libtcmalloc/libtcmalloc_minimal.so.4\n","        %cd /content\n","        !rm *.tar.gz Patch && rm -r /content/gperftools\n","    else:\n","        %env LD_PRELOAD=/content/gdrive/MyDrive/sd/libtcmalloc/libtcmalloc_minimal.so.4\n","\n","    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","    os.environ['PYTHONWARNINGS'] = 'ignore'\n","\n","print('\u001b[1;32mDone, proceed')\n","\n","\n","\n","import os\n","import time\n","from IPython.utils import capture\n","from IPython.display import clear_output\n","import wget\n","from subprocess import check_output\n","import urllib.request\n","import requests\n","import base64\n","from gdown.download import get_url_from_gdrive_confirmation\n","from urllib.parse import urlparse, parse_qs, unquote\n","from urllib.request import urlopen, Request\n","\n","\n","def getsrc(url):\n","    parsed_url = urlparse(url)\n","    if parsed_url.netloc == 'civitai.com':\n","        src='civitai'\n","    elif parsed_url.netloc == 'drive.google.com':\n","        src='gdrive'\n","    elif parsed_url.netloc == 'huggingface.co':\n","        src='huggingface'\n","    else:\n","        src='others'\n","    return src\n","\n","\n","\n","def get_name(url, gdrive):\n","    if not gdrive:\n","        response = requests.get(url, allow_redirects=False)\n","        if \"Location\" in response.headers:\n","            redirected_url = response.headers[\"Location\"]\n","            quer = parse_qs(urlparse(redirected_url).query)\n","            if \"response-content-disposition\" in quer:\n","                disp_val = quer[\"response-content-disposition\"][0].split(\";\")\n","                for vals in disp_val:\n","                    if vals.strip().startswith(\"filename=\"):\n","                        filenm=unquote(vals.split(\"=\", 1)[1].strip())\n","                        return filenm.replace(\"\\\"\",\"\")\n","    else:\n","        headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36\"}\n","        lnk=\"https://drive.google.com/uc?id={id}&export=download\".format(id=url[url.find(\"/d/\")+3:url.find(\"/view\")])\n","        res = requests.session().get(lnk, headers=headers, stream=True, verify=True)\n","        res = requests.session().get(get_url_from_gdrive_confirmation(res.text), headers=headers, stream=True, verify=True)\n","        content_disposition = six.moves.urllib_parse.unquote(res.headers[\"Content-Disposition\"])\n","        filenm = re.search(r\"filename\\*=UTF-8''(.*)\", content_disposition).groups()[0].replace(os.path.sep, \"_\")\n","        return filenm\n","\n","\n","\n","Model_Version = \"1.5\"\n","\n","with capture.capture_output() as cap:\n","  os.chdir('/content')\n","\n","\n","Path_to_HuggingFace= \"\"\n","\n","MODEL_PATH = \"\"\n","\n","MODEL_LINK = \"\"\n","\n","\n","if os.path.exists('/content/gdrive/MyDrive/Fast-Dreambooth/token.txt'):\n","  with open(\"/content/gdrive/MyDrive/Fast-Dreambooth/token.txt\") as f:\n","     token = f.read()\n","  authe=f'https://USER:{token}@'\n","else:\n","  authe=\"https://\"\n","\n","def downloadmodel():\n","\n","  if os.path.exists('/content/stable-diffusion-v1-5'):\n","    !rm -r /content/stable-diffusion-v1-5\n","  clear_output()\n","\n","  os.chdir('/content')\n","  clear_output()\n","  !mkdir /content/stable-diffusion-v1-5\n","  os.chdir('/content/stable-diffusion-v1-5')\n","  !git config --global init.defaultBranch main\n","  !git init\n","  !git lfs install --system --skip-repo\n","  !git remote add -f origin  \"https://huggingface.co/runwayml/stable-diffusion-v1-5\"\n","  !git config core.sparsecheckout true\n","  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\\n!vae/diffusion_pytorch_model.bin\\n!*.safetensors\\n!*.fp16.bin\\n!*.non_ema.bin\" > .git/info/sparse-checkout\n","  !git pull origin main\n","  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n","    !wget -q -O vae/diffusion_pytorch_model.bin https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.bin\n","    !rm -r .git\n","    !rm model_index.json\n","    time.sleep(1)\n","    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n","    os.chdir('/content')\n","    clear_output()\n","    print('\u001b[1;32mDONE !')\n","  else:\n","    while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n","         print('\u001b[1;31mSomething went wrong')\n","         time.sleep(5)\n","\n","def newdownloadmodel():\n","\n","  os.chdir('/content')\n","  clear_output()\n","  !mkdir /content/stable-diffusion-v2-768\n","  os.chdir('/content/stable-diffusion-v2-768')\n","  !git config --global init.defaultBranch main\n","  !git init\n","  !git lfs install --system --skip-repo\n","  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1\"\n","  !git config core.sparsecheckout true\n","  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\\n!*.fp16.bin\" > .git/info/sparse-checkout\n","  !git pull origin main\n","  !rm -r /content/stable-diffusion-v2-768/.git\n","  os.chdir('/content')\n","  clear_output()\n","  print('\u001b[1;32mDONE !')\n","\n","\n","def newdownloadmodelb():\n","\n","  os.chdir('/content')\n","  clear_output()\n","  !mkdir /content/stable-diffusion-v2-512\n","  os.chdir('/content/stable-diffusion-v2-512')\n","  !git config --global init.defaultBranch main\n","  !git init\n","  !git lfs install --system --skip-repo\n","  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base\"\n","  !git config core.sparsecheckout true\n","  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\\n!*.fp16.bin\" > .git/info/sparse-checkout\n","  !git pull origin main\n","  !rm -r /content/stable-diffusion-v2-512/.git\n","  os.chdir('/content')\n","  clear_output()\n","  print('\u001b[1;32mDONE !')\n","\n","\n","if Path_to_HuggingFace != \"\":\n","  if authe==\"https://\":\n","    textenc= f\"{authe}huggingface.co/{Path_to_HuggingFace}/resolve/main/text_encoder/pytorch_model.bin\"\n","    txtenc_size=urllib.request.urlopen(textenc).info().get('Content-Length', None)\n","  else:\n","    textenc= f\"https://huggingface.co/{Path_to_HuggingFace}/resolve/main/text_encoder/pytorch_model.bin\"\n","    req=urllib.request.Request(textenc)\n","    req.add_header('Authorization', f'Bearer {token}')\n","    txtenc_size=urllib.request.urlopen(req).info().get('Content-Length', None)\n","  if int(txtenc_size)> 670000000 :\n","    if os.path.exists('/content/stable-diffusion-custom'):\n","      !rm -r /content/stable-diffusion-custom\n","    clear_output()\n","    os.chdir('/content')\n","    clear_output()\n","    print(\"\u001b[1;32mV2\")\n","    !mkdir /content/stable-diffusion-custom\n","    os.chdir('/content/stable-diffusion-custom')\n","    !git config --global init.defaultBranch main\n","    !git init\n","    !git lfs install --system --skip-repo\n","    !git remote add -f origin  \"{authe}huggingface.co/{Path_to_HuggingFace}\"\n","    !git config core.sparsecheckout true\n","    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n","    !git pull origin main\n","    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","      !rm -r /content/stable-diffusion-custom/.git\n","      os.chdir('/content')\n","      MODEL_NAME=\"/content/stable-diffusion-custom\"\n","      clear_output()\n","      print('\u001b[1;32mDONE !')\n","    else:\n","      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","            print('\u001b[1;31mCheck the link you provided')\n","            time.sleep(5)\n","  else:\n","    if os.path.exists('/content/stable-diffusion-custom'):\n","      !rm -r /content/stable-diffusion-custom\n","    clear_output()\n","    os.chdir('/content')\n","    clear_output()\n","    print(\"\u001b[1;32mV1\")\n","    !mkdir /content/stable-diffusion-custom\n","    os.chdir('/content/stable-diffusion-custom')\n","    !git init\n","    !git lfs install --system --skip-repo\n","    !git remote add -f origin  \"{authe}huggingface.co/{Path_to_HuggingFace}\"\n","    !git config core.sparsecheckout true\n","    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n","    !git pull origin main\n","    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","      !rm -r /content/stable-diffusion-custom/.git\n","      !rm model_index.json\n","      time.sleep(1)\n","      wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n","      os.chdir('/content')\n","      MODEL_NAME=\"/content/stable-diffusion-custom\"\n","      clear_output()\n","      print('\u001b[1;32mDONE !')\n","    else:\n","      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","            print('\u001b[1;31mCheck the link you provided')\n","            time.sleep(5)\n","\n","elif MODEL_PATH !=\"\":\n","\n","  modelname=os.path.basename(MODEL_PATH)\n","  sftnsr=\"\"\n","  if modelname.split('.')[-1]=='safetensors':\n","    sftnsr=\"--from_safetensors\"\n","\n","  %cd /content\n","  clear_output()\n","  if os.path.exists(str(MODEL_PATH)):\n","    wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n","    print('\u001b[1;33mDetecting model version...')\n","    Custom_Model_Version=check_output('python det.py '+sftnsr+' --MODEL_PATH '+str(MODEL_PATH), shell=True).decode('utf-8').replace('\\n', '')\n","    clear_output()\n","    print('\u001b[1;32m'+Custom_Model_Version+' Detected')\n","    !rm det.py\n","    if Custom_Model_Version=='1.5':\n","      !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n","      !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$MODEL_PATH\" --dump_path stable-diffusion-custom --original_config_file config.yaml $sftnsr\n","      !rm /content/config.yaml\n","\n","    elif Custom_Model_Version=='V2.1-512px':\n","      !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n","      !python /content/convertodiff.py \"$MODEL_PATH\" /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1-base $sftnsr\n","      !rm /content/convertodiff.py\n","\n","    elif Custom_Model_Version=='V2.1-768px':\n","      !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n","      !python /content/convertodiff.py \"$MODEL_PATH\" /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1 $sftnsr\n","      !rm /content/convertodiff.py\n","\n","\n","    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","      clear_output()\n","      MODEL_NAME=\"/content/stable-diffusion-custom\"\n","      print('\u001b[1;32mDONE !')\n","    else:\n","      !rm -r /content/stable-diffusion-custom\n","      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","        print('\u001b[1;31mConversion error')\n","        time.sleep(5)\n","  else:\n","    while not os.path.exists(str(MODEL_PATH)):\n","       print('\u001b[1;31mWrong path, use the colab file explorer to copy the path')\n","       time.sleep(5)\n","\n","elif MODEL_LINK !=\"\":\n","    os.chdir('/content')\n","\n","    src=getsrc(MODEL_LINK)\n","\n","    if src=='civitai':\n","       modelname=get_name(str(MODEL_LINK), False)\n","    elif src=='gdrive':\n","       modelname=get_name(str(MODEL_LINK), True)\n","    else:\n","       modelname=os.path.basename(str(MODEL_LINK))\n","\n","    sftnsr=\"\"\n","    if modelname.split('.')[-1]!='safetensors':\n","      modelnm=\"model.ckpt\"\n","    else:\n","      modelnm=\"model.safetensors\"\n","      sftnsr=\"--from_safetensors\"\n","\n","    !gdown --fuzzy \"$MODEL_LINK\" -O $modelnm\n","\n","    if os.path.exists(modelnm):\n","      if os.path.getsize(modelnm) > 1810671599:\n","        wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n","        print('\u001b[1;33mDetecting model version...')\n","        Custom_Model_Version=check_output('python det.py '+sftnsr+' --MODEL_PATH '+modelnm, shell=True).decode('utf-8').replace('\\n', '')\n","        clear_output()\n","        print('\u001b[1;32m'+Custom_Model_Version+' Detected')\n","        !rm det.py\n","        if Custom_Model_Version=='1.5':\n","          !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n","          !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $modelnm --dump_path stable-diffusion-custom --original_config_file config.yaml $sftnsr\n","          !rm config.yaml\n","\n","        elif Custom_Model_Version=='V2.1-512px':\n","          !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n","          !python /content/convertodiff.py $modelnm /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1-base $sftnsr\n","          !rm convertodiff.py\n","\n","        elif Custom_Model_Version=='V2.1-768px':\n","          !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n","          !python /content/convertodiff.py $modelnm /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1 $sftnsr\n","          !rm convertodiff.py\n","\n","\n","        if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","          clear_output()\n","          MODEL_NAME=\"/content/stable-diffusion-custom\"\n","          print('\u001b[1;32mDONE !')\n","        else:\n","          !rm -r stable-diffusion-custom\n","          !rm $modelnm\n","          while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","            print('\u001b[1;31mConversion error')\n","            time.sleep(5)\n","      else:\n","        while os.path.getsize(modelnm) < 1810671599:\n","           print('\u001b[1;31mWrong link, check that the link is valid')\n","           time.sleep(5)\n","\n","else:\n","  if Model_Version==\"1.5\":\n","    if not os.path.exists('/content/stable-diffusion-v1-5'):\n","      downloadmodel()\n","      MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n","    else:\n","      MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n","      print(\"\u001b[1;32mThe v1.5 model already exists, using this model.\")\n","  elif Model_Version==\"V2.1-512px\":\n","    if not os.path.exists('/content/stable-diffusion-v2-512'):\n","      newdownloadmodelb()\n","      MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n","    else:\n","      MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n","      print(\"\u001b[1;32mThe v2-512px model already exists, using this model.\")\n","  elif Model_Version==\"V2.1-768px\":\n","    if not os.path.exists('/content/stable-diffusion-v2-768'):\n","      newdownloadmodel()\n","      MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n","    else:\n","      MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n","      print(\"\u001b[1;32mThe v2-768px model already exists, using this model.\")\n","\n","\n","\n","\n","\n","import os\n","from IPython.display import clear_output\n","from IPython.utils import capture\n","from os import listdir\n","from os.path import isfile\n","from subprocess import check_output\n","import wget\n","import time\n","\n","\n","try:\n","  MODEL_NAME\n","  pass\n","except:\n","  MODEL_NAME=\"\"\n","\n","PT=\"\"\n","\n","while Session_Name==\"\":\n","  print('\u001b[1;31mInput the Session Name:')\n","  Session_Name=input('')\n","Session_Name=Session_Name.replace(\" \",\"_\")\n","\n","\n","Session_Link_optional = \"\"\n","\n","\n","WORKSPACE='/content/gdrive/MyDrive/Fast-Dreambooth'\n","\n","if Session_Link_optional !=\"\":\n","  print('\u001b[1;32mDownloading session...')\n","  with capture.capture_output() as cap:\n","    %cd /content\n","    if not os.path.exists(str(WORKSPACE+'/Sessions')):\n","      %mkdir -p $WORKSPACE'/Sessions'\n","      time.sleep(1)\n","    %cd $WORKSPACE'/Sessions'\n","    !gdown --folder --remaining-ok -O $Session_Name  $Session_Link_optional\n","    %cd $Session_Name\n","    !rm -r instance_images\n","    !unzip instance_images.zip\n","    !rm -r captions\n","    !unzip captions.zip\n","    %cd /content\n","\n","\n","INSTANCE_NAME=Session_Name\n","OUTPUT_DIR=\"/content/models/\"+Session_Name\n","SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n","INSTANCE_DIR=SESSION_DIR+'/instance_images'\n","CAPTIONS_DIR=SESSION_DIR+'/captions'\n","MDLPTH=str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n","\n","if os.path.exists(str(SESSION_DIR)):\n","  mdls=[ckpt for ckpt in listdir(SESSION_DIR) if ckpt.split(\".\")[-1]==\"ckpt\"]\n","  if not os.path.exists(MDLPTH) and '.ckpt' in str(mdls):\n","\n","    def f(n):\n","      k=0\n","      for i in mdls:\n","        if k==n:\n","          !mv \"$SESSION_DIR/$i\" $MDLPTH\n","        k=k+1\n","\n","    k=0\n","    print('\u001b[1;33mNo final checkpoint model found, select which intermediary checkpoint to use, enter only the number, (000 to skip):\\n\u001b[1;34m')\n","\n","    for i in mdls:\n","      print(str(k)+'- '+i)\n","      k=k+1\n","    n=input()\n","    while int(n)>k-1:\n","      n=input()\n","    if n!=\"000\":\n","      f(int(n))\n","      print('\u001b[1;32mUsing the model '+ mdls[int(n)]+\" ...\")\n","      time.sleep(2)\n","    else:\n","      print('\u001b[1;32mSkipping the intermediary checkpoints.')\n","    del n\n","\n","with capture.capture_output() as cap:\n","  %cd /content\n","  resume=False\n","\n","if os.path.exists(str(SESSION_DIR)) and not os.path.exists(MDLPTH):\n","  print('\u001b[1;32mLoading session with no previous model, using the original model or the custom downloaded model')\n","  if MODEL_NAME==\"\":\n","    print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n","  else:\n","    print('\u001b[1;32mSession Loaded, proceed to uploading instance images')\n","\n","elif os.path.exists(MDLPTH):\n","  print('\u001b[1;32mSession found, loading the trained model ...')\n","  wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n","  print('\u001b[1;33mDetecting model version...')\n","  Model_Version=check_output('python det.py --MODEL_PATH '+MDLPTH, shell=True).decode('utf-8').replace('\\n', '')\n","  clear_output()\n","  print('\u001b[1;32m'+Model_Version+' Detected')\n","  !rm det.py\n","  if Model_Version=='1.5':\n","    !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n","    print('\u001b[1;32mSession found, loading the trained model ...')\n","    !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $MDLPTH --dump_path \"$OUTPUT_DIR\" --original_config_file config.yaml\n","    !rm /content/config.yaml\n","\n","  elif Model_Version=='V2.1-512px':\n","    !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n","    print('\u001b[1;32mSession found, loading the trained model ...')\n","    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1-base\n","    !rm /content/convertodiff.py\n","\n","  elif Model_Version=='V2.1-768px':\n","    !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n","    print('\u001b[1;32mSession found, loading the trained model ...')\n","    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1\n","    !rm /content/convertodiff.py\n","\n","\n","  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n","    resume=True\n","    clear_output()\n","    print('\u001b[1;32mSession loaded.')\n","  else:\n","    if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n","      print('\u001b[1;31mConversion error, if the error persists, remove the CKPT file from the current session folder')\n","\n","elif not os.path.exists(str(SESSION_DIR)):\n","    %mkdir -p \"$INSTANCE_DIR\"\n","    print('\u001b[1;32mCreating session...')\n","    if MODEL_NAME==\"\":\n","      print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n","    else:\n","      print('\u001b[1;32mSession created, proceed to uploading instance images')\n","\n","\n","\n","\n","import shutil\n","from google.colab import files\n","import time\n","from PIL import Image\n","from tqdm import tqdm\n","import ipywidgets as widgets\n","from io import BytesIO\n","import wget\n","\n","with capture.capture_output() as cap:\n","  %cd /content\n","  if not os.path.exists(\"/content/smart_crop.py\"):\n","    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/smart_crop.py')\n","  from smart_crop import *\n","\n","\n","Remove_existing_instance_images= True\n","\n","if Remove_existing_instance_images:\n","  if os.path.exists(str(INSTANCE_DIR)):\n","    !rm -r \"$INSTANCE_DIR\"\n","  if os.path.exists(str(CAPTIONS_DIR)):\n","    !rm -r \"$CAPTIONS_DIR\"\n","\n","if not os.path.exists(str(INSTANCE_DIR)):\n","  %mkdir -p \"$INSTANCE_DIR\"\n","if not os.path.exists(str(CAPTIONS_DIR)):\n","  %mkdir -p \"$CAPTIONS_DIR\"\n","\n","if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n","  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n","\n","\n","IMAGES_FOLDER_OPTIONAL=\"\"\n","\n","\n","Smart_Crop_images= True\n","Crop_size = 512\n","\n","\n","while IMAGES_FOLDER_OPTIONAL !=\"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n","  print('\u001b[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path :')\n","  IMAGES_FOLDER_OPTIONAL=input('')\n","\n","if IMAGES_FOLDER_OPTIONAL!=\"\":\n","  if os.path.exists(IMAGES_FOLDER_OPTIONAL+\"/.ipynb_checkpoints\"):\n","    %rm -r \"$IMAGES_FOLDER_OPTIONAL\"\"/.ipynb_checkpoints\"\n","\n","  with capture.capture_output() as cap:\n","    !mv $IMAGES_FOLDER_OPTIONAL/*.txt $CAPTIONS_DIR\n","  if Smart_Crop_images:\n","    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n","      extension = filename.split(\".\")[-1]\n","      identifier=filename.split(\".\")[0]\n","      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n","      file = Image.open(IMAGES_FOLDER_OPTIONAL+\"/\"+filename)\n","      width, height = file.size\n","      if file.size !=(Crop_size, Crop_size):\n","        image=crop_image(file, Crop_size)\n","        if extension.upper()==\"JPG\" or extension.upper()==\"jpg\":\n","            image[0] = image[0].convert(\"RGB\")\n","            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n","        else:\n","            image[0].save(new_path_with_file, format=extension.upper())\n","      else:\n","        !cp \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n","\n","  else:\n","    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n","      %cp -r \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n","\n","  print('\\n\u001b[1;32mDone, proceed to the next cell')\n","\n","\n","elif IMAGES_FOLDER_OPTIONAL ==\"\":\n","  up=\"\"\n","  uploaded = files.upload()\n","  for filename in uploaded.keys():\n","    if filename.split(\".\")[-1]==\"txt\":\n","      shutil.move(filename, CAPTIONS_DIR)\n","    up=[filename for filename in uploaded.keys() if filename.split(\".\")[-1]!=\"txt\"]\n","  if Smart_Crop_images:\n","    for filename in tqdm(up, bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n","      shutil.move(filename, INSTANCE_DIR)\n","      extension = filename.split(\".\")[-1]\n","      identifier=filename.split(\".\")[0]\n","      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n","      file = Image.open(new_path_with_file)\n","      width, height = file.size\n","      if file.size !=(Crop_size, Crop_size):\n","        image=crop_image(file, Crop_size)\n","        if extension.upper()==\"JPG\" or extension.upper()==\"jpg\":\n","            image[0] = image[0].convert(\"RGB\")\n","            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n","        else:\n","            image[0].save(new_path_with_file, format=extension.upper())\n","      clear_output()\n","  else:\n","    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n","      shutil.move(filename, INSTANCE_DIR)\n","      clear_output()\n","  print('\\n\u001b[1;32mDone, proceed to the next cell')\n","\n","with capture.capture_output() as cap:\n","  %cd \"$INSTANCE_DIR\"\n","  !find . -name \"* *\" -type f | rename 's/ /-/g'\n","  %cd \"$CAPTIONS_DIR\"\n","  !find . -name \"* *\" -type f | rename 's/ /-/g'\n","\n","  %cd $SESSION_DIR\n","  !rm instance_images.zip captions.zip\n","  !zip -r instance_images instance_images\n","  !zip -r captions captions\n","  %cd /content\n"]},{"cell_type":"markdown","metadata":{"id":"Vh_GOlFZjWwj"},"source":["# Ide a szöveg fölé kell majd a képeket feltölteni!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DVOHrfSZiKuK"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CTRGOZPxiKr1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"29h5ZVvUiKo0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uP6hJsDuiKl4"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vk6HB-RaiKi1"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ctTF2Ll1iOIz"},"source":["#Itt a második futatás parancs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-9QbkfAVYYU"},"outputs":[],"source":["\n","import os\n","from IPython.display import clear_output\n","from google.colab import runtime\n","from subprocess import getoutput\n","import time\n","import random\n","\n","if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n","  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n","\n","if os.path.exists(CAPTIONS_DIR+\"/.ipynb_checkpoints\"):\n","  %rm -r $CAPTIONS_DIR\"/.ipynb_checkpoints\"\n","\n","Resume_Training = False\n","\n","if resume and not Resume_Training:\n","  print('\u001b[1;31mOverwrite your previously trained model ? answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?\u001b[0m')\n","  while True:\n","    ansres=input('')\n","    if ansres=='no':\n","      Resume_Training = True\n","      break\n","    elif ansres=='yes':\n","      Resume_Training = False\n","      resume= False\n","      break\n","\n","while not Resume_Training and MODEL_NAME==\"\":\n","  print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n","  time.sleep(5)\n","\n","\n","MODELT_NAME=MODEL_NAME\n","\n","UNet_Training_Steps=1800\n","UNet_Learning_Rate = 2e-6\n","untlr=UNet_Learning_Rate\n","\n","\n","Text_Encoder_Training_Steps=350\n","\n","Text_Encoder_Learning_Rate = 1e-6\n","txlr=Text_Encoder_Learning_Rate\n","\n","\n","\n","trnonltxt=\"\"\n","if UNet_Training_Steps==0:\n","   trnonltxt=\"--train_only_text_encoder\"\n","\n","Seed=''\n","\n","ofstnse=\"\"\n","Offset_Noise = False\n","\n","if Offset_Noise:\n","  ofstnse=\"--offset_noise\"\n","\n","External_Captions = False\n","\n","extrnlcptn=\"\"\n","if External_Captions:\n","  extrnlcptn=\"--external_captions\"\n","\n","Resolution = \"512\"\n","Res=int(Resolution)\n","\n","\n","fp16 = True\n","\n","if Seed =='' or Seed=='0':\n","  Seed=random.randint(1, 999999)\n","else:\n","  Seed=int(Seed)\n","\n","if fp16:\n","  prec=\"fp16\"\n","else:\n","  prec=\"no\"\n","\n","precision=prec\n","\n","resuming=\"\"\n","if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n","  MODELT_NAME=OUTPUT_DIR\n","  print('\u001b[1;32mResuming Training...\u001b[0m')\n","  resuming=\"Yes\"\n","elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n","  print('\u001b[1;31mPrevious model not found, training a new model...\u001b[0m')\n","  MODELT_NAME=MODEL_NAME\n","  while MODEL_NAME==\"\":\n","    print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n","    time.sleep(5)\n","\n","V2=False\n","if os.path.getsize(MODELT_NAME+\"/text_encoder/pytorch_model.bin\") > 670901463:\n","  V2=True\n","\n","s = getoutput('nvidia-smi')\n","GCUNET=\"--gradient_checkpointing\"\n","TexRes=Res\n","if Res<=768:\n","  GCUNET=\"\"\n","\n","if V2:\n","  if Res>704:\n","    GCUNET=\"--gradient_checkpointing\"\n","  if Res>576:\n","    TexRes=576\n","\n","if 'A100' in s :\n","   GCUNET=\"\"\n","   TexRes=Res\n","\n","\n","Enable_text_encoder_training= True\n","\n","if Text_Encoder_Training_Steps==0 :\n","   Enable_text_encoder_training= False\n","else:\n","  stptxt=Text_Encoder_Training_Steps\n","\n","\n","Save_Checkpoint_Every_n_Steps = False\n","Save_Checkpoint_Every=500\n","if Save_Checkpoint_Every==None:\n","  Save_Checkpoint_Every=1\n","\n","stp=0\n","Start_saving_from_the_step=500\n","if Start_saving_from_the_step==None:\n","  Start_saving_from_the_step=0\n","if (Start_saving_from_the_step < 200):\n","  Start_saving_from_the_step=Save_Checkpoint_Every\n","stpsv=Start_saving_from_the_step\n","if Save_Checkpoint_Every_n_Steps:\n","  stp=Save_Checkpoint_Every\n","\n","Disconnect_after_training=False\n","\n","\n","def dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n","\n","    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n","    $trnonltxt \\\n","    $extrnlcptn \\\n","    $ofstnse \\\n","    --image_captions_filename \\\n","    --train_text_encoder \\\n","    --dump_only_text_encoder \\\n","    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n","    --instance_data_dir=\"$INSTANCE_DIR\" \\\n","    --output_dir=\"$OUTPUT_DIR\" \\\n","    --captions_dir=\"$CAPTIONS_DIR\" \\\n","    --instance_prompt=\"$PT\" \\\n","    --seed=$Seed \\\n","    --resolution=$TexRes \\\n","    --mixed_precision=$precision \\\n","    --train_batch_size=1 \\\n","    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n","    --use_8bit_adam \\\n","    --learning_rate=$txlr \\\n","    --lr_scheduler=\"linear\" \\\n","    --lr_warmup_steps=0 \\\n","    --max_train_steps=$Training_Steps\n","\n","def train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps):\n","    clear_output()\n","    if resuming==\"Yes\":\n","      print('\u001b[1;32mResuming Training...\u001b[0m')\n","    print('\u001b[1;33mTraining the UNet...\u001b[0m')\n","    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n","    $extrnlcptn \\\n","    $ofstnse \\\n","    --image_captions_filename \\\n","    --train_only_unet \\\n","    --save_starting_step=$stpsv \\\n","    --save_n_steps=$stp \\\n","    --Session_dir=$SESSION_DIR \\\n","    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n","    --instance_data_dir=\"$INSTANCE_DIR\" \\\n","    --output_dir=\"$OUTPUT_DIR\" \\\n","    --captions_dir=\"$CAPTIONS_DIR\" \\\n","    --instance_prompt=\"$PT\" \\\n","    --seed=$Seed \\\n","    --resolution=$Res \\\n","    --mixed_precision=$precision \\\n","    --train_batch_size=1 \\\n","    --gradient_accumulation_steps=1 $GCUNET \\\n","    --use_8bit_adam \\\n","    --learning_rate=$untlr \\\n","    --lr_scheduler=\"linear\" \\\n","    --lr_warmup_steps=0 \\\n","    --max_train_steps=$Training_Steps\n","\n","\n","if Enable_text_encoder_training :\n","  print('\u001b[1;33mTraining the text encoder...\u001b[0m')\n","  if os.path.exists(OUTPUT_DIR+'/'+'text_encoder_trained'):\n","    %rm -r $OUTPUT_DIR\"/text_encoder_trained\"\n","  dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n","\n","\n","if UNet_Training_Steps!=0:\n","  train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps=UNet_Training_Steps)\n","\n","if UNet_Training_Steps==0 and Text_Encoder_Training_Steps==0 :\n","  print('\u001b[1;32mNothing to do')\n","else:\n","  if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n","    prc=\"--fp16\" if precision==\"fp16\" else \"\"\n","    !python /content/diffusers/scripts/convertosdv2.py $prc $OUTPUT_DIR $SESSION_DIR/$Session_Name\".ckpt\"\n","    clear_output()\n","    if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n","      clear_output()\n","      print(\"\u001b[1;32mDONE, the CKPT model is in your Gdrive in the sessions folder\")\n","      if Disconnect_after_training :\n","        time.sleep(20)\n","        runtime.unassign()\n","    else:\n","      print(\"\u001b[1;31mSomething went wrong\")\n","  else:\n","    print(\"\u001b[1;31mSomething went wrong\")\n","\n","\n","\n","\n","\n","from slugify import slugify\n","from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n","from huggingface_hub import create_repo\n","from IPython.display import display_markdown\n","from IPython.display import clear_output\n","from IPython.utils import capture\n","from google.colab import files\n","import shutil\n","import time\n","import os\n","\n","Upload_sample_images = False\n","\n","Name_of_your_concept = Session_Name\n","if(Name_of_your_concept == \"\"):\n","  Name_of_your_concept = Session_Name\n","Name_of_your_concept=Name_of_your_concept.replace(\" \",\"-\")\n","\n","if hf_token_write ==\"\":\n","  print('\u001b[1;32mYour Hugging Face write access token : ')\n","  hf_token_write=input()\n","\n","hf_token = hf_token_write\n","\n","api = HfApi()\n","your_username = api.whoami(token=hf_token)[\"name\"]\n","\n","repo_id = f\"{your_username}/{slugify(Name_of_your_concept)}\"\n","output_dir = f'/content/models/'+INSTANCE_NAME\n","\n","def bar(prg):\n","    br=\"\u001b[1;33mUploading to HuggingFace : \" '\u001b[0m|'+'█' * prg + ' ' * (25-prg)+'| ' +str(prg*4)+ \"%\"\n","    return br\n","\n","print(\"\u001b[1;32mLoading...\")\n","\n","NM=\"False\"\n","if os.path.getsize(OUTPUT_DIR+\"/text_encoder/pytorch_model.bin\") > 670901463:\n","  NM=\"True\"\n","\n","with capture.capture_output() as cap:\n","  if NM==\"False\":\n","    %cd $OUTPUT_DIR\n","    !rm -r safety_checker feature_extractor .git\n","    !rm model_index.json\n","    !git init\n","    !git lfs install --system --skip-repo\n","    !git remote add -f origin  \"https://USER:{hf_token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n","    !git config core.sparsecheckout true\n","    !echo -e \"feature_extractor\\nsafety_checker\\nmodel_index.json\" > .git/info/sparse-checkout\n","    !git pull origin main\n","    !rm -r .git\n","    %cd /content\n","  else:\n","    %cd $OUTPUT_DIR\n","    !rm -r feature_extractor .git\n","    !git init\n","    !git lfs install --system --skip-repo\n","    !git remote add -f origin  \"https://USER:{hf_token}@huggingface.co/stabilityai/stable-diffusion-2-1\"\n","    !git config core.sparsecheckout true\n","    !echo -e \"feature_extractor\" > .git/info/sparse-checkout\n","    !git pull origin main\n","    !rm -r .git\n","    %cd /content\n","\n","\n","image_string = \"\"\n","\n","if os.path.exists('/content/sample_images'):\n","  !rm -r /content/sample_images\n","Samples=\"/content/sample_images\"\n","!mkdir $Samples\n","clear_output()\n","\n","if Upload_sample_images:\n","\n","  print(\"\u001b[1;32mUpload Sample images of the model\")\n","  uploaded = files.upload()\n","  for filename in uploaded.keys():\n","    shutil.move(filename, Samples)\n","  %cd $Samples\n","  !find . -name \"* *\" -type f | rename 's/ /_/g'\n","  %cd /content\n","  clear_output()\n","\n","  print(bar(1))\n","\n","  images_upload = os.listdir(Samples)\n","  instance_prompt_list = []\n","  for i, image in enumerate(images_upload):\n","      image_string = f'''\n","  {image_string}![{i}](https://huggingface.co/{repo_id}/resolve/main/sample_images/{image})\n","      '''\n","\n","readme_text = f'''---\n","license: creativeml-openrail-m\n","tags:\n","- text-to-image\n","- stable-diffusion\n","---\n","### {Name_of_your_concept} Dreambooth model trained by {api.whoami(token=hf_token)[\"name\"]} with [TheLastBen's fast-DreamBooth](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb) notebook\n","\n","\n","Test the concept via A1111 Colab [fast-Colab-A1111](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast_stable_diffusion_AUTOMATIC1111.ipynb)\n","\n","Sample pictures of this concept:\n","{image_string}\n","'''\n","#Save the readme to a file\n","readme_file = open(\"README.md\", \"w\")\n","readme_file.write(readme_text)\n","readme_file.close()\n","\n","operations = [\n","  CommitOperationAdd(path_in_repo=\"README.md\", path_or_fileobj=\"README.md\"),\n","  CommitOperationAdd(path_in_repo=f\"{Session_Name}.ckpt\",path_or_fileobj=MDLPTH)\n","\n","]\n","create_repo(repo_id,private=True, token=hf_token)\n","\n","api.create_commit(\n","  repo_id=repo_id,\n","  operations=operations,\n","  commit_message=f\"Upload the concept {Name_of_your_concept} embeds and token\",\n","  token=hf_token\n",")\n","\n","api.upload_folder(\n","  folder_path=OUTPUT_DIR+\"/feature_extractor\",\n","  path_in_repo=\"feature_extractor\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","clear_output()\n","print(bar(4))\n","\n","if NM==\"False\":\n","  api.upload_folder(\n","    folder_path=OUTPUT_DIR+\"/safety_checker\",\n","    path_in_repo=\"safety_checker\",\n","    repo_id=repo_id,\n","    token=hf_token\n","  )\n","\n","clear_output()\n","print(bar(8))\n","\n","\n","api.upload_folder(\n","  folder_path=OUTPUT_DIR+\"/scheduler\",\n","  path_in_repo=\"scheduler\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","clear_output()\n","print(bar(9))\n","\n","api.upload_folder(\n","  folder_path=OUTPUT_DIR+\"/text_encoder\",\n","  path_in_repo=\"text_encoder\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","clear_output()\n","print(bar(12))\n","\n","api.upload_folder(\n","  folder_path=OUTPUT_DIR+\"/tokenizer\",\n","  path_in_repo=\"tokenizer\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","clear_output()\n","print(bar(13))\n","\n","api.upload_folder(\n","  folder_path=OUTPUT_DIR+\"/unet\",\n","  path_in_repo=\"unet\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","clear_output()\n","print(bar(21))\n","\n","api.upload_folder(\n","  folder_path=OUTPUT_DIR+\"/vae\",\n","  path_in_repo=\"vae\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","clear_output()\n","print(bar(23))\n","\n","api.upload_file(\n","  path_or_fileobj=OUTPUT_DIR+\"/model_index.json\",\n","  path_in_repo=\"model_index.json\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","clear_output()\n","print(bar(24))\n","\n","api.upload_folder(\n","  folder_path=Samples,\n","  path_in_repo=\"sample_images\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","clear_output()\n","print(bar(25))\n","\n","display_markdown(f'''## Your concept was saved successfully. [Click here to access it](https://huggingface.co/{repo_id})''', raw=True)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb","timestamp":1699687817884}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
